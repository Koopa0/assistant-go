# LangChain æ•´åˆç³»çµ±

é€™å€‹åŒ…å¯¦ç¾äº† Assistant èˆ‡ LangChain-Go çš„æ·±åº¦æ•´åˆï¼Œæä¾›å®Œæ•´çš„ AI å·¥ä½œæµæ”¯æ´å’Œé«˜ç´š RAG åŠŸèƒ½ã€‚

## æ¶æ§‹æ¦‚è¿°

LangChain æ•´åˆç³»çµ±æ¡ç”¨æ¨¡å¡ŠåŒ–è¨­è¨ˆï¼Œæ”¯æ´å¤šç¨® AI å·¥ä½œæµï¼š

```
langchain/
â”œâ”€â”€ client.go            # LangChain å®¢æˆ¶ç«¯
â”œâ”€â”€ service.go           # LangChain æœå‹™å±¤
â”œâ”€â”€ adapter.go           # Assistant é©é…å™¨
â”œâ”€â”€ agents/              # æ™ºèƒ½ä»£ç†ç³»çµ±
â”‚   â”œâ”€â”€ base.go          # ä»£ç†åŸºç¤é¡
â”‚   â”œâ”€â”€ development.go   # é–‹ç™¼å°ˆå®¶ä»£ç†
â”‚   â”œâ”€â”€ database.go      # è³‡æ–™åº«å°ˆå®¶ä»£ç†
â”‚   â”œâ”€â”€ infrastructure.go # åŸºç¤è¨­æ–½ä»£ç†
â”‚   â””â”€â”€ research.go      # ç ”ç©¶ä»£ç†
â”œâ”€â”€ chains/              # AI å·¥ä½œæµéˆ
â”‚   â”œâ”€â”€ base.go          # éˆåŸºç¤é¡
â”‚   â”œâ”€â”€ sequential.go    # é †åºåŸ·è¡Œéˆ
â”‚   â”œâ”€â”€ parallel.go      # ä¸¦è¡ŒåŸ·è¡Œéˆ
â”‚   â”œâ”€â”€ conditional.go   # æ¢ä»¶åŸ·è¡Œéˆ
â”‚   â”œâ”€â”€ rag.go           # RAG éˆ
â”‚   â””â”€â”€ rag_enhanced.go  # å¢å¼· RAG éˆ
â”œâ”€â”€ memory/              # è¨˜æ†¶ç³»çµ±
â”‚   â”œâ”€â”€ manager.go       # è¨˜æ†¶ç®¡ç†å™¨
â”‚   â”œâ”€â”€ shortterm.go     # çŸ­æœŸè¨˜æ†¶
â”‚   â”œâ”€â”€ longterm.go      # é•·æœŸè¨˜æ†¶
â”‚   â””â”€â”€ personalization.go # å€‹äººåŒ–è¨˜æ†¶
â”œâ”€â”€ vectorstore/         # å‘é‡å­˜å„²
â”‚   â””â”€â”€ pgvector.go      # PostgreSQL å‘é‡å­˜å„²
â””â”€â”€ documentloader/      # æ–‡æª”è™•ç†
    â””â”€â”€ loader.go        # å¤šæ ¼å¼æ–‡æª”åŠ è¼‰å™¨
```

## è¨­è¨ˆç†å¿µ

### ğŸ¤– AI åŸç”Ÿé›†æˆ
LangChain æ•´åˆç³»çµ±åŸç”Ÿæ”¯æ´ AI å·¥ä½œæµï¼š
- **åŸç”Ÿ LLM æ”¯æ´**: ç›´æ¥ä½¿ç”¨ LangChain çš„ LLM æŠ½è±¡
- **å·¥ä½œæµç·¨æ’**: ç”¨ Chains å»ºæ§‹è¤‡é›œ AI å·¥ä½œæµ
- **å‘é‡æª¢ç´¢**: å…§å»ºèªç¾©æœå°‹å’Œ RAG åŠŸèƒ½
- **è¨˜æ†¶ç®¡ç†**: é•·çŸ­æœŸè¨˜æ†¶çš„æ™ºèƒ½ç®¡ç†

### ğŸ”— ç„¡ç¸«æ©‹æ¥
èˆ‡ Assistant æ ¸å¿ƒç³»çµ±çš„å®Œç¾æ•´åˆï¼š
- **é›™å‘å…¼å®¹**: æ”¯æ´ LangChain å’ŒåŸç”Ÿ Assistant API
- **ç‚ºå¯®å€’é™**: è‡ªå‹•åœ¨ LangChain å’ŒåŸç”Ÿå¯¦ç¾é–“åˆ‡æ›
- **é…ç½®é©…å‹•**: é€šéé…ç½®æ§åˆ¶ä½¿ç”¨å„ªå…ˆç´š
- **ç‹€æ…‹åŒæ­¥**: ä¿æŒè¨˜æ†¶å’Œä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§

### ğŸš€ é«˜ç´š RAG
ä¼æ¥­ç´šçš„æª¢ç´¢å¢å¼·ç”Ÿæˆï¼š
- **å¤šæ¨¡æ…‹æª¢ç´¢**: æ”¯æ´æ–‡æœ¬ã€ä»£ç¢¼ã€åœ–åƒç­‰æ ¼å¼
- **æ™ºèƒ½åˆ†å‰²**: è‡ªé©æ‡‰æ–‡æª”åˆ†å‰²ç­–ç•¥
- **å±¤æ¬¡æª¢ç´¢**: å¯¦ç¾ç²—ç²¾åº¦çš„å±¤æ¬¡æª¢ç´¢
- **ä¸Šä¸‹æ–‡åé‡**: æ ¹æ“šä¸Šä¸‹æ–‡èª¿æ•´æª¢ç´¢ç­–ç•¥

## æ ¸å¿ƒä»‹é¢

### LangChain å®¢æˆ¶ç«¯

```go
// LangChainClient æä¾› LangChain åŠŸèƒ½çš„çµ±ä¸€å…¥å£
type LangChainClient interface {
    // åŸºç¤ LLM åŠŸèƒ½
    GenerateText(ctx context.Context, prompt string, options *GenerateOptions) (*GenerateResponse, error)
    
    // å·¥ä½œæµéˆåŸ·è¡Œ
    RunChain(ctx context.Context, chainName string, inputs map[string]any) (*ChainResult, error)
    
    // æ™ºèƒ½ä»£ç†äº¤äº’
    InvokeAgent(ctx context.Context, agentName string, input *AgentInput) (*AgentResponse, error)
    
    // å‘é‡å­˜å„²æ“ä½œ
    StoreDocuments(ctx context.Context, docs []Document) error
    SearchSimilar(ctx context.Context, query string, opts *SearchOptions) ([]Document, error)
    
    // è¨˜æ†¶ç®¡ç†
    StoreMemory(ctx context.Context, sessionID string, memory *Memory) error
    RetrieveMemory(ctx context.Context, sessionID string) (*Memory, error)
    
    // ç”Ÿå‘½é€±æœŸç®¡ç†
    Initialize(ctx context.Context, config *Config) error
    Close() error
}

// LangChainClientImpl å¯¦ç¾ LangChain å®¢æˆ¶ç«¯
type LangChainClientImpl struct {
    // LangChain çµ„ä»¶
    llm          llms.Model
    embeddings   embeddings.Embedder
    vectorStore  vectorstores.VectorStore
    
    // æ™ºèƒ½ä»£ç†
    agents       map[string]agents.Agent
    agentExecutor *agents.Executor
    
    // å·¥ä½œæµéˆ
    chains       map[string]chains.Chain
    
    // è¨˜æ†¶ç³»çµ±
    memory       schema.Memory
    
    // é…ç½®å’Œæ—¥èªŒ
    config       *Config
    logger       *slog.Logger
}

func NewLangChainClient(config *Config, logger *slog.Logger) (LangChainClient, error) {
    client := &LangChainClientImpl{
        agents: make(map[string]agents.Agent),
        chains: make(map[string]chains.Chain),
        config: config,
        logger: logger,
    }
    
    // åˆå§‹åŒ– LLM
    llm, err := client.initializeLLM(config.LLM)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize LLM: %w", err)
    }
    client.llm = llm
    
    // åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings, err := client.initializeEmbeddings(config.Embeddings)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize embeddings: %w", err)
    }
    client.embeddings = embeddings
    
    // åˆå§‹åŒ–å‘é‡å­˜å„²
    vectorStore, err := client.initializeVectorStore(config.VectorStore)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize vector store: %w", err)
    }
    client.vectorStore = vectorStore
    
    // åˆå§‹åŒ–æ™ºèƒ½ä»£ç†
    err = client.initializeAgents(config.Agents)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize agents: %w", err)
    }
    
    // åˆå§‹åŒ–å·¥ä½œæµéˆ
    err = client.initializeChains(config.Chains)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize chains: %w", err)
    }
    
    return client, nil
}
```

### æ™ºèƒ½ä»£ç†ç³»çµ±

```go
// LangChainAgent åœ¨ LangChain ä¸­çš„æ™ºèƒ½ä»£ç†å¯¦ç¾
type LangChainAgent struct {
    name        string
    description string
    
    // LangChain çµ„ä»¶
    llm         llms.Model
    tools       []tools.Tool
    memory      schema.Memory
    
    // Assistant é›†æˆ
    assistantAgent core.Agent
    
    // åŸ·è¡Œå™¨
    executor    *agents.Executor
    
    // é…ç½®
    config      *AgentConfig
    logger      *slog.Logger
}

func NewDevelopmentAgent(config *AgentConfig, logger *slog.Logger) (*LangChainAgent, error) {
    agent := &LangChainAgent{
        name:        "development-expert",
        description: "Specialized agent for software development tasks",
        config:      config,
        logger:      logger,
    }
    
    // åˆå§‹åŒ– LLM
    llm, err := initializeLLM(config.LLM)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize LLM: %w", err)
    }
    agent.llm = llm
    
    // åˆå§‹åŒ–é–‹ç™¼å·¥å…·
    devTools, err := agent.initializeDevelopmentTools()
    if err != nil {
        return nil, fmt.Errorf("failed to initialize development tools: %w", err)
    }
    agent.tools = devTools
    
    // åˆå§‹åŒ–è¨˜æ†¶
    memory := memory.NewBufferMemory()
    agent.memory = memory
    
    // å‰µå»º Agent åŸ·è¡Œå™¨
    executor, err := agents.NewExecutor(
        agents.NewReActAgent(
            llm,
            devTools,
            agents.WithMemory(memory),
            agents.WithMaxIterations(10),
        ),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to create agent executor: %w", err)
    }
    agent.executor = executor
    
    return agent, nil
}

func (la *LangChainAgent) ProcessTask(ctx context.Context, task *Task) (*TaskResult, error) {
    // æº–å‚™è¼¸å…¥
    inputs := map[string]any{
        "input": task.Description,
        "context": task.Context,
    }
    
    // åŸ·è¡Œ Agent
    result, err := la.executor.Call(ctx, inputs)
    if err != nil {
        return nil, fmt.Errorf("agent execution failed: %w", err)
    }
    
    // è§£æçµæœ
    output, ok := result["output"].(string)
    if !ok {
        return nil, fmt.Errorf("invalid agent output format")
    }
    
    taskResult := &TaskResult{
        Output:      output,
        Actions:     la.extractActions(result),
        Reasoning:   la.extractReasoning(result),
        Confidence:  la.calculateConfidence(result),
        Metadata:    result,
    }
    
    return taskResult, nil
}

func (la *LangChainAgent) initializeDevelopmentTools() ([]tools.Tool, error) {
    var devTools []tools.Tool
    
    // ä»£ç¢¼åˆ†æå·¥å…·
    codeAnalyzer, err := tools.NewCodeAnalyzer()
    if err != nil {
        return nil, fmt.Errorf("failed to create code analyzer: %w", err)
    }
    devTools = append(devTools, codeAnalyzer)
    
    // Git æ“ä½œå·¥å…·
    gitTool, err := tools.NewGitTool()
    if err != nil {
        return nil, fmt.Errorf("failed to create git tool: %w", err)
    }
    devTools = append(devTools, gitTool)
    
    // æ–‡ä»¶ç³»çµ±å·¥å…·
    fileSystemTool, err := tools.NewFileSystemTool()
    if err != nil {
        return nil, fmt.Errorf("failed to create filesystem tool: %w", err)
    }
    devTools = append(devTools, fileSystemTool)
    
    // ç·¨è­¯å’Œæ¸¬è©¦å·¥å…·
    buildTool, err := tools.NewBuildTool()
    if err != nil {
        return nil, fmt.Errorf("failed to create build tool: %w", err)
    }
    devTools = append(devTools, buildTool)
    
    return devTools, nil
}
```

### RAG å¢å¼·éˆ

```go
// EnhancedRAGChain å¯¦ç¾é«˜ç´š RAG åŠŸèƒ½
type EnhancedRAGChain struct {
    name        string
    description string
    
    // æ ¸å¿ƒçµ„ä»¶
    llm         llms.Model
    embeddings  embeddings.Embedder
    vectorStore vectorstores.VectorStore
    retriever   schema.Retriever
    
    // æ–‡æª”è™•ç†
    documentLoader *DocumentLoader
    textSplitter   textsplitter.TextSplitter
    
    // å¢å¼·åŠŸèƒ½
    contextEnricher   *ContextEnricher
    queryExpander     *QueryExpander
    resultRanker      *ResultRanker
    sourceTracker     *SourceTracker
    
    // ç·©å­˜
    cache       *cache.LRU[string, *RAGResult]
    
    // é…ç½®
    config      *RAGConfig
    logger      *slog.Logger
}

func NewEnhancedRAGChain(config *RAGConfig, logger *slog.Logger) (*EnhancedRAGChain, error) {
    chain := &EnhancedRAGChain{
        name:        "enhanced-rag",
        description: "Enhanced Retrieval-Augmented Generation chain",
        config:      config,
        logger:      logger,
        cache:       cache.NewLRU[string, *RAGResult](config.CacheSize),
    }
    
    // åˆå§‹åŒ– LLM
    llm, err := initializeLLM(config.LLM)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize LLM: %w", err)
    }
    chain.llm = llm
    
    // åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings, err := initializeEmbeddings(config.Embeddings)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize embeddings: %w", err)
    }
    chain.embeddings = embeddings
    
    // åˆå§‹åŒ–å‘é‡å­˜å„²
    vectorStore, err := initializeVectorStore(config.VectorStore)
    if err != nil {
        return nil, fmt.Errorf("failed to initialize vector store: %w", err)
    }
    chain.vectorStore = vectorStore
    
    // å‰µå»ºæª¢ç´¢å™¨
    retriever := vectorstores.ToRetriever(
        vectorStore,
        config.TopK,
        vectorstores.WithScoreThreshold(config.ScoreThreshold),
    )
    chain.retriever = retriever
    
    // åˆå§‹åŒ–å¢å¼·çµ„ä»¶
    chain.initializeEnhancedComponents()
    
    return chain, nil
}

func (erc *EnhancedRAGChain) ProcessQuery(ctx context.Context, query string, opts *QueryOptions) (*RAGResult, error) {
    // æª¢æŸ¥ç·©å­˜
    if result, exists := erc.cache.Get(query); exists {
        erc.logger.Debug("Cache hit for RAG query", slog.String("query", query))
        return result, nil
    }
    
    // 1. æŸ¥è©¢æ“´å±•
    expandedQueries := erc.queryExpander.ExpandQuery(query, opts.Context)
    
    // 2. å¤šè·¯æª¢ç´¢
    allDocs := make([]schema.Document, 0)
    for _, expandedQuery := range expandedQueries {
        docs, err := erc.retriever.GetRelevantDocuments(ctx, expandedQuery)
        if err != nil {
            erc.logger.Warn("Retrieval failed for expanded query", 
                slog.String("query", expandedQuery),
                slog.Any("error", err))
            continue
        }
        allDocs = append(allDocs, docs...)
    }
    
    // 3. çµæœå»é‡å’Œæ’åº
    uniqueDocs := erc.deduplicateDocuments(allDocs)
    rankedDocs := erc.resultRanker.RankDocuments(uniqueDocs, query, opts.Context)
    
    // 4. ä¸Šä¸‹æ–‡å¯ŒåŒ–
    enrichedContext := erc.contextEnricher.EnrichContext(rankedDocs, opts.Context)
    
    // 5. ç”Ÿæˆæœ€çµ‚å›ç­”
    prompt := erc.buildRAGPrompt(query, enrichedContext, opts)
    response, err := erc.llm.Call(ctx, prompt)
    if err != nil {
        return nil, fmt.Errorf("LLM generation failed: %w", err)
    }
    
    // 6. çµæœå°è£
    result := &RAGResult{
        Query:           query,
        Response:        response,
        SourceDocuments: rankedDocs,
        Sources:         erc.sourceTracker.ExtractSources(rankedDocs),
        Confidence:      erc.calculateConfidence(response, rankedDocs),
        Metadata: map[string]interface{}{
            "expanded_queries": expandedQueries,
            "total_docs":      len(allDocs),
            "unique_docs":     len(uniqueDocs),
            "final_docs":      len(rankedDocs),
        },
    }
    
    // 7. ç·©å­˜çµæœ
    erc.cache.Set(query, result)
    
    return result, nil
}

func (erc *EnhancedRAGChain) IngestDocuments(ctx context.Context, source DocumentSource) error {
    // 1. åŠ è¼‰æ–‡æª”
    documents, err := erc.documentLoader.LoadFromSource(ctx, source)
    if err != nil {
        return fmt.Errorf("failed to load documents: %w", err)
    }
    
    // 2. æ–‡æª”åˆ†å‰²
    var chunks []schema.Document
    for _, doc := range documents {
        docChunks, err := erc.textSplitter.SplitDocuments([]schema.Document{doc})
        if err != nil {
            erc.logger.Warn("Failed to split document", 
                slog.String("source", doc.Metadata["source"].(string)),
                slog.Any("error", err))
            continue
        }
        chunks = append(chunks, docChunks...)
    }
    
    // 3. ç”ŸæˆåµŒå…¥
    embeddings, err := erc.embeddings.EmbedDocuments(ctx, 
        documentsToStrings(chunks))
    if err != nil {
        return fmt.Errorf("failed to generate embeddings: %w", err)
    }
    
    // 4. å­˜å„²åˆ°å‘é‡å­˜å„²
    err = erc.vectorStore.AddDocuments(ctx, chunks, 
        vectorstores.WithEmbeddings(embeddings))
    if err != nil {
        return fmt.Errorf("failed to store documents: %w", err)
    }
    
    erc.logger.Info("Successfully ingested documents", 
        slog.Int("document_count", len(documents)),
        slog.Int("chunk_count", len(chunks)))
    
    return nil
}
```

### å‘é‡å­˜å„²æ•´åˆ

```go
// PGVectorStore å¯¦ç¾ LangChain VectorStore æ¥å£
type PGVectorStore struct {
    // Assistant æ ¸å¿ƒçµ„ä»¶
    client    postgres.Client
    embedder  embeddings.Embedder
    
    // LangChain å…¼å®¹æ€§
    schema.VectorStore
    
    // é…ç½®
    tableName    string
    dimensions   int
    distanceFunc string
    
    logger *slog.Logger
}

func NewPGVectorStore(client postgres.Client, embedder embeddings.Embedder, 
                     config *VectorStoreConfig, logger *slog.Logger) *PGVectorStore {
    return &PGVectorStore{
        client:       client,
        embedder:     embedder,
        tableName:    config.TableName,
        dimensions:   config.Dimensions,
        distanceFunc: config.DistanceFunction,
        logger:       logger,
    }
}

// AddDocuments å¯¦ç¾ LangChain VectorStore.AddDocuments
func (pvs *PGVectorStore) AddDocuments(ctx context.Context, docs []schema.Document, 
                                      options ...vectorstores.Option) ([]string, error) {
    opts := vectorstores.NewOptions(options...)
    
    // ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆå¦‚æœæœªæä¾›ï¼‰
    var embeddings [][]float64
    if opts.Embeddings != nil {
        embeddings = opts.Embeddings
    } else {
        texts := make([]string, len(docs))
        for i, doc := range docs {
            texts[i] = doc.PageContent
        }
        
        embeds, err := pvs.embedder.EmbedDocuments(ctx, texts)
        if err != nil {
            return nil, fmt.Errorf("failed to generate embeddings: %w", err)
        }
        embeddings = embeds
    }
    
    // è½‰æ›ç‚º Assistant æ ¼å¼
    var ids []string
    for i, doc := range docs {
        contentID := generateContentID()
        ids = append(ids, contentID)
        
        // è½‰æ› metadata ç‚º JSON
        metadataJSON, err := json.Marshal(doc.Metadata)
        if err != nil {
            pvs.logger.Warn("Failed to marshal metadata", slog.Any("error", err))
            metadataJSON = []byte("{}")
        }
        
        var metadata map[string]interface{}
        if err := json.Unmarshal(metadataJSON, &metadata); err != nil {
            metadata = make(map[string]interface{})
        }
        
        // å­˜å„²åˆ° Assistant æ•¸æ“šåº«
        _, err = pvs.client.CreateEmbedding(ctx, 
            "langchain_document",
            contentID,
            doc.PageContent,
            embeddings[i],
            metadata,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to store document %d: %w", i, err)
        }
    }
    
    return ids, nil
}

// SimilaritySearch å¯¦ç¾ LangChain VectorStore.SimilaritySearch
func (pvs *PGVectorStore) SimilaritySearch(ctx context.Context, query string, 
                                          numDocuments int, options ...vectorstores.Option) ([]schema.Document, error) {
    opts := vectorstores.NewOptions(options...)
    
    // ç”ŸæˆæŸ¥è©¢åµŒå…¥
    queryEmbedding, err := pvs.embedder.EmbedQuery(ctx, query)
    if err != nil {
        return nil, fmt.Errorf("failed to embed query: %w", err)
    }
    
    // åŸ·è¡Œç›¸ä¼¼æ€§æœå°‹
    threshold := 0.0
    if opts.ScoreThreshold != nil {
        threshold = *opts.ScoreThreshold
    }
    
    results, err := pvs.client.SearchSimilarEmbeddings(ctx, 
        queryEmbedding, "langchain_document", numDocuments, threshold)
    if err != nil {
        return nil, fmt.Errorf("similarity search failed: %w", err)
    }
    
    // è½‰æ›å› LangChain æ–‡æª”æ ¼å¼
    docs := make([]schema.Document, len(results))
    for i, result := range results {
        docs[i] = schema.Document{
            PageContent: result.Record.ContentText,
            Metadata:    result.Record.Metadata,
        }
        
        // æ·»åŠ ç›¸ä¼¼æ€§åˆ†æ•¸
        if docs[i].Metadata == nil {
            docs[i].Metadata = make(map[string]interface{})
        }
        docs[i].Metadata["similarity_score"] = result.Similarity
        docs[i].Metadata["content_id"] = result.Record.ContentID
    }
    
    return docs, nil
}
```

## è¨˜æ†¶ç®¡ç†

### æ•´åˆè¨˜æ†¶ç³»çµ±

```go
// IntegratedMemoryManager çµåˆ LangChain å’Œ Assistant è¨˜æ†¶
type IntegratedMemoryManager struct {
    // LangChain è¨˜æ†¶
    langchainMemory   schema.Memory
    
    // Assistant è¨˜æ†¶
    assistantMemory   *core.MemorySystem
    
    // åŒæ­¥ç®¡ç†
    syncManager       *MemorySyncManager
    
    // å€‹äººåŒ–ç®¡ç†
    personalization  *PersonalizationManager
    
    config *MemoryConfig
    logger *slog.Logger
}

func NewIntegratedMemoryManager(assistantMemory *core.MemorySystem, 
                               config *MemoryConfig, logger *slog.Logger) *IntegratedMemoryManager {
    manager := &IntegratedMemoryManager{
        assistantMemory: assistantMemory,
        config:         config,
        logger:         logger,
    }
    
    // åˆå§‹åŒ– LangChain è¨˜æ†¶
    if config.LangChainMemoryType == "buffer" {
        manager.langchainMemory = memory.NewBufferMemory()
    } else if config.LangChainMemoryType == "conversation_summary" {
        manager.langchainMemory = memory.NewConversationSummaryMemory(config.LLM)
    }
    
    // åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
    manager.syncManager = NewMemorySyncManager(manager.langchainMemory, 
                                              assistantMemory, logger)
    
    // åˆå§‹åŒ–å€‹äººåŒ–ç®¡ç†å™¨
    manager.personalization = NewPersonalizationManager(assistantMemory, config, logger)
    
    return manager
}

func (imm *IntegratedMemoryManager) StoreInteraction(ctx context.Context, 
                                                    sessionID string, 
                                                    interaction *Interaction) error {
    // 1. å­˜å„²åˆ° LangChain è¨˜æ†¶
    err := imm.langchainMemory.SaveContext(ctx, map[string]any{
        "input":  interaction.Input,
        "output": interaction.Output,
    })
    if err != nil {
        imm.logger.Warn("Failed to store to LangChain memory", slog.Any("error", err))
    }
    
    // 2. å­˜å„²åˆ° Assistant è¨˜æ†¶
    episode := &memory.Episode{
        SessionID:   sessionID,
        UserID:      interaction.UserID,
        Interaction: interaction,
        Context:     interaction.Context,
        Timestamp:   time.Now(),
    }
    
    err = imm.assistantMemory.StoreEpisode(ctx, episode)
    if err != nil {
        imm.logger.Warn("Failed to store to Assistant memory", slog.Any("error", err))
    }
    
    // 3. åŒæ­¥è¨˜æ†¶
    go imm.syncManager.SyncMemories(ctx, sessionID)
    
    // 4. æ›´æ–°å€‹äººåŒ–è¨­å®š
    go imm.personalization.UpdateFromInteraction(ctx, interaction)
    
    return nil
}

func (imm *IntegratedMemoryManager) RetrieveContext(ctx context.Context, 
                                                   sessionID string, 
                                                   query string) (*MemoryContext, error) {
    // 1. å¾ LangChain è¨˜æ†¶ç²å–ä¸Šä¸‹æ–‡
    langchainContext, err := imm.langchainMemory.LoadMemoryVariables(ctx, 
                                                                   map[string]any{"input": query})
    if err != nil {
        imm.logger.Warn("Failed to load LangChain memory", slog.Any("error", err))
    }
    
    // 2. å¾ Assistant è¨˜æ†¶ç²å–ç›¸é—œæƒ…ç¯€
    episodes, err := imm.assistantMemory.RetrieveRelevantEpisodes(ctx, &memory.EpisodicQuery{
        SessionID: sessionID,
        Content:   query,
        Limit:     10,
    })
    if err != nil {
        imm.logger.Warn("Failed to retrieve Assistant episodes", slog.Any("error", err))
    }
    
    // 3. ç²å–å€‹äººåŒ–è¨­å®š
    personalizations := imm.personalization.GetPersonalizations(ctx, sessionID)
    
    // 4. ç¶œåˆä¸Šä¸‹æ–‡
    context := &MemoryContext{
        SessionID:        sessionID,
        LangChainContext: langchainContext,
        Episodes:         episodes,
        Personalizations: personalizations,
        RetrievalTime:    time.Now(),
    }
    
    return context, nil
}
```

## æ–‡æª”è™•ç†

### å¤šæ ¼å¼æ–‡æª”åŠ è¼‰å™¨

```go
// DocumentLoader æ”¯æ´å¤šç¨®æ–‡æª”æ ¼å¼çš„æ™ºèƒ½åŠ è¼‰å™¨
type DocumentLoader struct {
    // åŠ è¼‰å™¨è¨»å†Šè¡¨
    loaders map[string]FormatLoader
    
    // æ–‡æœ¬åˆ†å‰²å™¨
    splitters map[string]textsplitter.TextSplitter
    
    // å…§å®¹è­˜åˆ¥
    contentDetector *ContentDetector
    
    // ç·©å­˜
    cache *cache.LRU[string, []schema.Document]
    
    config *DocumentLoaderConfig
    logger *slog.Logger
}

type FormatLoader interface {
    Load(ctx context.Context, source DocumentSource) ([]schema.Document, error)
    SupportedExtensions() []string
    Priority() int
}

func NewDocumentLoader(config *DocumentLoaderConfig, logger *slog.Logger) *DocumentLoader {
    dl := &DocumentLoader{
        loaders:   make(map[string]FormatLoader),
        splitters: make(map[string]textsplitter.TextSplitter),
        cache:     cache.NewLRU[string, []schema.Document](config.CacheSize),
        config:    config,
        logger:    logger,
    }
    
    // è¨»å†Šå…§å»ºåŠ è¼‰å™¨
    dl.registerBuiltinLoaders()
    
    // åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
    dl.initializeSplitters()
    
    // åˆå§‹åŒ–å…§å®¹è­˜åˆ¥å™¨
    dl.contentDetector = NewContentDetector()
    
    return dl
}

func (dl *DocumentLoader) LoadFromSource(ctx context.Context, source DocumentSource) ([]schema.Document, error) {
    // æª¢æŸ¥ç·©å­˜
    cacheKey := dl.generateCacheKey(source)
    if docs, exists := dl.cache.Get(cacheKey); exists {
        dl.logger.Debug("Cache hit for document source", slog.String("source", source.String()))
        return docs, nil
    }
    
    var allDocs []schema.Document
    
    switch source.Type {
    case DocumentSourceTypeFile:
        docs, err := dl.loadFromFile(ctx, source.Path)
        if err != nil {
            return nil, fmt.Errorf("failed to load file: %w", err)
        }
        allDocs = docs
        
    case DocumentSourceTypeDirectory:
        docs, err := dl.loadFromDirectory(ctx, source.Path)
        if err != nil {
            return nil, fmt.Errorf("failed to load directory: %w", err)
        }
        allDocs = docs
        
    case DocumentSourceTypeURL:
        docs, err := dl.loadFromURL(ctx, source.URL)
        if err != nil {
            return nil, fmt.Errorf("failed to load URL: %w", err)
        }
        allDocs = docs
        
    case DocumentSourceTypeString:
        doc := schema.Document{
            PageContent: source.Content,
            Metadata: map[string]interface{}{
                "source": "string_input",
                "type":   "text",
            },
        }
        allDocs = []schema.Document{doc}
        
    default:
        return nil, fmt.Errorf("unsupported document source type: %v", source.Type)
    }
    
    // ç·©å­˜çµæœ
    dl.cache.Set(cacheKey, allDocs)
    
    dl.logger.Info("Loaded documents from source", 
        slog.String("source", source.String()),
        slog.Int("document_count", len(allDocs)))
    
    return allDocs, nil
}

func (dl *DocumentLoader) loadFromFile(ctx context.Context, filePath string) ([]schema.Document, error) {
    // æª¢æ¸¬æ–‡ä»¶æ ¼å¼
    ext := filepath.Ext(filePath)
    format := dl.contentDetector.DetectFormat(filePath, ext)
    
    // ç²å–å°æ‡‰åŠ è¼‰å™¨
    loader, exists := dl.loaders[format]
    if !exists {
        return nil, fmt.Errorf("no loader found for format: %s", format)
    }
    
    // åŠ è¼‰æ–‡æª”
    source := DocumentSource{
        Type: DocumentSourceTypeFile,
        Path: filePath,
    }
    
    docs, err := loader.Load(ctx, source)
    if err != nil {
        return nil, fmt.Errorf("loader failed for %s: %w", format, err)
    }
    
    // æ–‡æœ¬åˆ†å‰²
    if splitter, exists := dl.splitters[format]; exists {
        splitDocs, err := splitter.SplitDocuments(docs)
        if err != nil {
            dl.logger.Warn("Text splitting failed, using original documents", 
                slog.String("format", format),
                slog.Any("error", err))
        } else {
            docs = splitDocs
        }
    }
    
    return docs, nil
}

func (dl *DocumentLoader) registerBuiltinLoaders() {
    // æ–‡æœ¬æ–‡ä»¶åŠ è¼‰å™¨
    dl.loaders["txt"] = &TextFileLoader{}
    dl.loaders["md"] = &MarkdownLoader{}
    
    // ä»£ç¢¼æ–‡ä»¶åŠ è¼‰å™¨
    dl.loaders["go"] = &CodeFileLoader{Language: "go"}
    dl.loaders["py"] = &CodeFileLoader{Language: "python"}
    dl.loaders["js"] = &CodeFileLoader{Language: "javascript"}
    dl.loaders["ts"] = &CodeFileLoader{Language: "typescript"}
    
    // é…ç½®æ–‡ä»¶åŠ è¼‰å™¨
    dl.loaders["yaml"] = &YAMLLoader{}
    dl.loaders["json"] = &JSONLoader{}
    
    // Web æ–‡ä»¶åŠ è¼‰å™¨
    dl.loaders["html"] = &HTMLLoader{}
    
    // PDF åŠ è¼‰å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if dl.config.EnablePDFLoader {
        dl.loaders["pdf"] = &PDFLoader{}
    }
}

func (dl *DocumentLoader) initializeSplitters() {
    // é»˜èªæ–‡æœ¬åˆ†å‰²å™¨
    dl.splitters["default"] = textsplitter.NewRecursiveCharacter(
        textsplitter.WithChunkSize(dl.config.DefaultChunkSize),
        textsplitter.WithChunkOverlap(dl.config.DefaultChunkOverlap),
    )
    
    // Markdown åˆ†å‰²å™¨
    dl.splitters["md"] = textsplitter.NewMarkdownTextSplitter(
        textsplitter.WithChunkSize(dl.config.MarkdownChunkSize),
        textsplitter.WithChunkOverlap(dl.config.MarkdownChunkOverlap),
    )
    
    // ä»£ç¢¼åˆ†å‰²å™¨
    codeSplitter := textsplitter.NewCodeTextSplitter(
        textsplitter.WithChunkSize(dl.config.CodeChunkSize),
        textsplitter.WithChunkOverlap(dl.config.CodeChunkOverlap),
    )
    dl.splitters["go"] = codeSplitter
    dl.splitters["py"] = codeSplitter
    dl.splitters["js"] = codeSplitter
    dl.splitters["ts"] = codeSplitter
}
```

## é…ç½®ç®¡ç†

### LangChain æ•´åˆé…ç½®

```yaml
langchain:
  # åŸºç¤é…ç½®
  enabled: true
  fallback_to_native: true
  
  # LLM é…ç½®
  llm:
    provider: "openai"  # openai, anthropic, cohere
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2048
    
  # åµŒå…¥æ¨¡å‹é…ç½®
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    dimensions: 1536
    
  # å‘é‡å­˜å„²é…ç½®
  vectorstore:
    type: "pgvector"
    table_name: "langchain_embeddings"
    distance_function: "cosine"
    
  # Agent é…ç½®
  agents:
    development:
      enabled: true
      max_iterations: 10
      early_stopping_method: "generate"
      tools:
        - "code_analyzer"
        - "git_operations"
        - "file_system"
        - "build_tools"
        
    database:
      enabled: true
      max_iterations: 8
      tools:
        - "sql_executor"
        - "schema_analyzer"
        - "query_optimizer"
        
  # RAG é…ç½®
  rag:
    enabled: true
    top_k: 5
    score_threshold: 0.7
    cache_size: 1000
    
    # æ–‡æª”è™•ç†
    document_processing:
      chunk_size: 1000
      chunk_overlap: 200
      enable_pdf: true
      supported_formats:
        - "txt"
        - "md"
        - "go"
        - "py"
        - "js"
        - "ts"
        - "yaml"
        - "json"
        - "html"
        
  # è¨˜æ†¶é…ç½®
  memory:
    type: "conversation_summary"  # buffer, conversation_summary
    max_token_limit: 2000
    return_messages: true
    
    # Assistant è¨˜æ†¶æ•´åˆ
    assistant_integration:
      enabled: true
      sync_interval: "5m"
      personalization: true
```

## æ€§èƒ½å„ªåŒ–

### æ™ºèƒ½ç·©å­˜ç­–ç•¥

```go
// LangChainCacheManager ç‚º LangChain æ“ä½œæä¾›æ™ºèƒ½ç·©å­˜
type LangChainCacheManager struct {
    // å¤šå±¤ç·©å­˜
    l1Cache    *cache.LRU[string, interface{}]  // å…§å­˜ç·©å­˜
    l2Cache    *cache.Redis                     // Redis ç·©å­˜
    vectorCache *cache.LRU[string, []schema.Document] // å‘é‡ç·©å­˜
    
    // ç·©å­˜ç­–ç•¥
    strategies map[CacheType]CacheStrategy
    
    // çµ±è¨ˆ
    stats *CacheStats
    
    config *CacheConfig
    logger *slog.Logger
}

func (lcm *LangChainCacheManager) CacheLLMResponse(ctx context.Context, 
                                                  prompt string, 
                                                  response string, 
                                                  metadata map[string]interface{}) {
    // ç”Ÿæˆç·©å­˜éµ
    key := lcm.generateLLMCacheKey(prompt, metadata)
    
    // åˆ¤æ–·ç·©å­˜ç­–ç•¥
    strategy := lcm.strategies[CacheTypeLLM]
    ttl := strategy.CalculateTTL(response, metadata)
    
    // L1 ç·©å­˜ï¼ˆå…§å­˜ï¼‰
    lcm.l1Cache.Set(key, response)
    
    // L2 ç·©å­˜ï¼ˆRedisï¼‰
    if lcm.l2Cache != nil {
        lcm.l2Cache.Set(ctx, key, response, ttl)
    }
    
    lcm.stats.RecordCacheSet(CacheTypeLLM)
}

func (lcm *LangChainCacheManager) GetCachedLLMResponse(ctx context.Context, 
                                                      prompt string, 
                                                      metadata map[string]interface{}) (string, bool) {
    key := lcm.generateLLMCacheKey(prompt, metadata)
    
    // å…ˆæª¢æŸ¥ L1 ç·©å­˜
    if response, exists := lcm.l1Cache.Get(key); exists {
        lcm.stats.RecordCacheHit(CacheTypeLLM, CacheLevelL1)
        return response.(string), true
    }
    
    // å†æª¢æŸ¥ L2 ç·©å­˜
    if lcm.l2Cache != nil {
        if response, err := lcm.l2Cache.Get(ctx, key); err == nil && response != "" {
            // å›å¡« L1 ç·©å­˜
            lcm.l1Cache.Set(key, response)
            lcm.stats.RecordCacheHit(CacheTypeLLM, CacheLevelL2)
            return response, true
        }
    }
    
    lcm.stats.RecordCacheMiss(CacheTypeLLM)
    return "", false
}

func (lcm *LangChainCacheManager) CacheVectorSearchResults(ctx context.Context, 
                                                          query string, 
                                                          results []schema.Document, 
                                                          metadata map[string]interface{}) {
    key := lcm.generateVectorCacheKey(query, metadata)
    
    // ç·©å­˜å‘é‡æœå°‹çµæœ
    lcm.vectorCache.Set(key, results)
    
    lcm.stats.RecordCacheSet(CacheTypeVector)
}

func (lcm *LangChainCacheManager) GetCachedVectorSearchResults(ctx context.Context, 
                                                              query string, 
                                                              metadata map[string]interface{}) ([]schema.Document, bool) {
    key := lcm.generateVectorCacheKey(query, metadata)
    
    if results, exists := lcm.vectorCache.Get(key); exists {
        lcm.stats.RecordCacheHit(CacheTypeVector, CacheLevelL1)
        return results, true
    }
    
    lcm.stats.RecordCacheMiss(CacheTypeVector)
    return nil, false
}
```

## ç›£æ§å’Œè¨ºæ–·

### LangChain æ•´åˆæŒ‡æ¨™

```go
// LangChainMetrics ç›£æ§ LangChain æ•´åˆçš„æ•ˆèƒ½æŒ‡æ¨™
type LangChainMetrics struct {
    // LLM æŒ‡æ¨™
    LLMRequestCount      int64
    LLMResponseTime      time.Duration
    LLMTokenUsage        int64
    LLMErrorRate         float64
    
    // Agent æŒ‡æ¨™
    AgentExecutions      map[string]int64
    AgentSuccessRate     map[string]float64
    AgentExecutionTime   map[string]time.Duration
    
    // RAG æŒ‡æ¨™
    RAGQueryCount        int64
    RAGResponseTime      time.Duration
    RAGRetrievalAccuracy float64
    
    // å‘é‡å­˜å„²æŒ‡æ¨™
    VectorStoreSize      int64
    VectorSearchTime     time.Duration
    VectorSearchAccuracy float64
    
    // ç·©å­˜æŒ‡æ¨™
    CacheHitRate         map[string]float64
    CacheMemoryUsage     int64
    
    mutex sync.RWMutex
}

func (lm *LangChainMetrics) RecordLLMRequest(duration time.Duration, tokens int64, success bool) {
    lm.mutex.Lock()
    defer lm.mutex.Unlock()
    
    lm.LLMRequestCount++
    lm.LLMResponseTime = updateRunningAverage(lm.LLMResponseTime, duration, lm.LLMRequestCount)
    lm.LLMTokenUsage += tokens
    
    if !success {
        lm.LLMErrorRate = updateErrorRate(lm.LLMErrorRate, lm.LLMRequestCount)
    }
}

func (lm *LangChainMetrics) GenerateHealthReport() *LangChainHealthReport {
    lm.mutex.RLock()
    defer lm.mutex.RUnlock()
    
    report := &LangChainHealthReport{
        Timestamp: time.Now(),
        Overall:   HealthStatusHealthy,
        Components: make(map[string]ComponentHealth),
    }
    
    // LLM å¥åº·æª¢æŸ¥
    llmHealth := ComponentHealth{
        Status: HealthStatusHealthy,
        Metrics: map[string]interface{}{
            "request_count":   lm.LLMRequestCount,
            "avg_response_time": lm.LLMResponseTime,
            "error_rate":      lm.LLMErrorRate,
            "token_usage":     lm.LLMTokenUsage,
        },
    }
    
    if lm.LLMErrorRate > 0.1 {
        llmHealth.Status = HealthStatusDegraded
        llmHealth.Issues = append(llmHealth.Issues, "High LLM error rate")
    }
    
    if lm.LLMResponseTime > 10*time.Second {
        llmHealth.Status = HealthStatusDegraded
        llmHealth.Issues = append(llmHealth.Issues, "Slow LLM response time")
    }
    
    report.Components["llm"] = llmHealth
    
    // Agent å¥åº·æª¢æŸ¥
    agentHealth := lm.assessAgentHealth()
    report.Components["agents"] = agentHealth
    
    // RAG å¥åº·æª¢æŸ¥
    ragHealth := lm.assessRAGHealth()
    report.Components["rag"] = ragHealth
    
    // ç¢ºå®šæ•´é«”å¥åº·ç‹€æ…‹
    report.Overall = lm.determineOverallHealth(llmHealth, agentHealth, ragHealth)
    
    return report
}
```

## æœ€ä½³å¯¦è¸

### 1. LangChain æ•´åˆåŸå‰‡

- **æ¸¸å»¶åŠ è¼‰**: åªåœ¨éœ€è¦æ™‚æ‰åˆå§‹åŒ– LangChain çµ„ä»¶
- **ç‚ºå¯®å€’é™**: ç‚º LangChain ä¸å¯ç”¨æ™‚æä¾›åŸç”Ÿå¯¦ç¾
- **ç‹€æ…‹åŒæ­¥**: ä¿æŒ LangChain å’Œ Assistant è¨˜æ†¶çš„åŒæ­¥
- **è³‡æºç®¡ç†**: æ­£ç¢ºé‡‹æ”¾ LangChain è³‡æºé˜²æ­¢æ´©æ¼

### 2. RAG å„ªåŒ–å»ºè­°

- **åˆ†å±¤æª¢ç´¢**: å¯¦ç¾ç²—ç²¾åº¦çš„å±¤æ¬¡æª¢ç´¢ç­–ç•¥
- **æŸ¥è©¢æ“´å±•**: ä½¿ç”¨åŒç¾©è©å’Œç›¸é—œè©æ“´å±•æŸ¥è©¢
- **çµæœé‡æ’**: åŸºæ–¼ä¸Šä¸‹æ–‡ç›¸é—œæ€§é‡æ–°æ’åº
- **ç·©å­˜ç­–ç•¥**: åˆç†ç·©å­˜çµæœä»¥æé«˜æ€§èƒ½

### 3. æ€§èƒ½èª¿å„ª

- **æ‰¹é‡è™•ç†**: åˆä½µå¤šå€‹è«‹æ±‚ä»¥æ¸›å°‘é–‹éŠ·
- **é€£æ¥æ± åŒ–**: é‡ç”¨ LLM é€£æ¥ä»¥æé«˜ååé‡
- **ç•°æ­¥è™•ç†**: ä½¿ç”¨éåŒæ­¥æ¨¡å¼è™•ç†é•·æ™‚é–“æ“ä½œ
- **è³‡æºç›£æ§**: ç›£æ§è³‡æºä½¿ç”¨ä¸¦åŠæ™‚èª¿æ•´

---

*LangChain æ•´åˆç³»çµ±ç‚º Assistant æä¾›äº†å¼·å¤§çš„ AI å·¥ä½œæµèƒ½åŠ›ï¼Œé€šéæ·±åº¦æ•´åˆå’Œæ™ºèƒ½å„ªåŒ–ï¼Œå¯¦ç¾äº†é«˜æ•ˆã€ç©©å®šçš„ä¼æ¥­ç´š AI é–‹ç™¼åŠ©æ‰‹ã€‚*